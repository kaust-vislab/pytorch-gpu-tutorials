{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Performance with Data Augmentation\n",
    "\n",
    "In this tutorial, you will learn how to use data augmentation techniques to expand the set of available training data and significantly improve the performance of the standard LeNet5 CNN developed in the [previous tutorial](./notebooks/mnist-tutorial).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up an account with Kaggle (Optional, but recommended!)\n",
    "\n",
    "### 1. Register for an account with Kaggle\n",
    "\n",
    "In order to download Kaggle competition data you will first need to create a [Kaggle](https://www.kaggle.com/) account.\n",
    "\n",
    "### 2. Create an API key\n",
    "\n",
    "Once you have registered for a Kaggle account you will need to create some [API credentials](https://github.com/Kaggle/kaggle-api#api-credentials) in order to be able to use the `kaggle` CLI to download data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the MNIST data\n",
    "If you have cloned the GitHub repository and are running this notebook on your local machine or are using Binder to run this notebook in the cloud, then the data has already been downloaded for you! If you are using Google Colab to run this notebook, then you will need to download the data before proceeding.\n",
    "\n",
    "## Downloading the data from Kaggle\n",
    "If you have a Kaggle account and API key, then you can provide your Kaggle username and API key in the cell below and execute the code to download the Kaggle [Digit Recognizer: Learn computer vision with the famous MNIST data](https://www.kaggle.com/c/digit-recognizer) competition data. **Before attempting to download the competition data you will need to login to your Kaggle account and accept the rules for this competition.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export KAGGLE_USERNAME=\"YOUR_USERNAME\"\n",
    "export KAGGLE_KEY=\"YOUR_API_KEY\"\n",
    "kaggle competitions download -c digit-recognizer -p ../data/raw/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data from GitHub\n",
    "If you are running this notebook using Google Colab but did not want to bother with setting up a Kaggle account and API key, then you can dowload the data from our GitHub repository by running the code in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "TRAIN_URL = \"https://raw.githubusercontent.com/kaust-vislab/pytorch-tutorials/master/data/raw/mnist/train.csv\"\n",
    "TEST_URL = \"https://raw.githubusercontent.com/kaust-vislab/pytorch-tutorials/master/data/raw/mnist/test.csv\"\n",
    "SAMPLE_SUBMISSION_URL = \"https://raw.githubusercontent.com/kaust-vislab/pytorch-tutorials/master/data/raw/mnist/sample_submission.csv\"\n",
    "\n",
    "\n",
    "def fetch_mnist_data():\n",
    "    if not os.path.isdir(\"../data/raw/mnist/\"):\n",
    "        os.makedirs(\"../data/raw/mnist/\")\n",
    "    \n",
    "    with open(\"../data/raw/mnist/train.csv\", 'wb') as f:\n",
    "        response = requests.get(TRAIN_URL)\n",
    "        f.write(response.content)\n",
    "        \n",
    "    with open(\"../data/raw/mnist/test.csv\", 'wb') as f:\n",
    "        response = requests.get(TEST_URL)\n",
    "        f.write(response.content)\n",
    "    \n",
    "    with open(\"../data/raw/mnist/sample_submission.csv\", 'wb') as f:\n",
    "        response = requests.get(SAMPLE_SUBMISSION_URL)\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_mnist_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ../data/raw/mnist/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_arr = np.loadtxt(\"../data/raw/mnist/train.csv\", delimiter=',', skiprows=1, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training data into training and validation subsets\n",
    "\n",
    "First step is to split the raw training data into training and validation datasets. The validation dataset will be used to help us prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_prng = np.random.RandomState(42)\n",
    "training_features, validation_features, training_target, validation_target = (\n",
    "    model_selection.train_test_split(mnist_arr[:, 1:],\n",
    "                                     mnist_arr[:, 0],\n",
    "                                     test_size=0.10,\n",
    "                                     random_state=_prng)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom `DataSet` class to handle transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSetWithTransforms(data.Dataset):\n",
    "    \n",
    "    def __init__(self, features, target, feature_transforms=None):\n",
    "        super().__init__()\n",
    "        self._features = features\n",
    "        self._target = torch.from_numpy(target).long()\n",
    "        self._feature_transforms = feature_transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self._feature_transforms is None:\n",
    "            features = self._features[index]\n",
    "        else: \n",
    "            features = self._feature_transforms(self._features[index])\n",
    "        target = self._target[index]\n",
    "        return (features, target) \n",
    "    \n",
    "    def __len__(self):\n",
    "        n_samples, _ = self._features.shape\n",
    "        return n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation should only apply to training data\n",
    "_feature_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda array: array.reshape((28, 28, 1))),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), shear=15, scale=(1.0, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "training_dataset = DataSetWithTransforms(training_features, training_target, _feature_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation should not be applied to validation data\n",
    "_feature_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda array: array.reshape((28, 28, 1))),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "validation_dataset = DataSetWithTransforms(validation_features, validation_target, _feature_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a custom DataLoader for training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    \n",
    "    def __init__(self, data_loader, f):\n",
    "        self._data_loader = data_loader\n",
    "        self._f = f\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._data_loader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in iter(self._data_loader):\n",
    "            yield self._f(*batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "_batch_size = 32\n",
    "_training_data_loader = data.DataLoader(training_dataset, batch_size=_batch_size, shuffle=True)\n",
    "training_data_loader = WrappedDataLoader(_training_data_loader, lambda X, y: (X.to(DEVICE), y.to(DEVICE)))\n",
    "_validation_data_loader = data.DataLoader(validation_dataset, batch_size=1024)\n",
    "validation_data_loader = WrappedDataLoader(_validation_data_loader, lambda X, y: (X.to(DEVICE), y.to(DEVICE)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring transformed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 6, sharex=True, sharey=True, figsize=(20, 20))\n",
    "for i in range(5):\n",
    "    for j in range(6):\n",
    "        if j == 0:\n",
    "            _ = axes[i, j].imshow(training_features[i].reshape((28, 28)), cmap=\"gray\")\n",
    "        else:\n",
    "            _ = axes[i, j].imshow(training_dataset[i][0][0], cmap=\"gray\")\n",
    "        \n",
    "        if i == 0 and j == 0:\n",
    "            axes[i, j].set_title(\"Original Digit\")\n",
    "        if i == 0 and j > 0:\n",
    "            axes[i, j].set_title(f\"Augmented Digit {j}\")        \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _checkpoint(epoch, model_fn, opt, path):\n",
    "    kwargs = {\"epoch\": epoch,\n",
    "              \"model_state_dict\": model_fn.state_dict(),\n",
    "              \"optimizer_state_dict\": opt.state_dict()}\n",
    "    torch.save(kwargs, path)\n",
    "\n",
    "\n",
    "def _partial_fit(model_fn, loss_fn, X_batch, y_batch, opt):\n",
    "    # forward pass\n",
    "    loss = loss_fn(model_fn(X_batch), y_batch)\n",
    "\n",
    "    # back propagation\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad() # don't forget to reset the gradient after each batch!\n",
    "\n",
    "\n",
    "def fit(model_fn, loss_fn, training_data_loader, opt, validation_data_loader=None, number_epochs=1, path=\"checkpoint.pkl\"):\n",
    "    lowest_validation_loss = np.inf # initialize validation loss for checkpointing!\n",
    "    for epoch in range(number_epochs):\n",
    "        model_fn.train()\n",
    "        for X_batch, y_batch in training_data_loader:\n",
    "            _partial_fit(model_fn, loss_fn, X_batch, y_batch, opt)\n",
    "        \n",
    "        # compute validation loss after each training epoch\n",
    "        if validation_data_loader is not None:\n",
    "            model_fn.eval()\n",
    "            with torch.no_grad():\n",
    "                batch_losses, batch_sizes = zip(*[(loss_fn(model_fn(X), y), len(X)) for X, y in validation_data_loader])\n",
    "                validation_loss = np.sum(np.multiply(batch_losses, batch_sizes)) / np.sum(batch_sizes)\n",
    "                if validation_loss < lowest_validation_loss:\n",
    "                    print(f\"Training epoch: {epoch}, Lowest validation loss: {validation_loss}\")\n",
    "                    _checkpoint(epoch, model_fn, opt, path)\n",
    "                    lowest_validation_loss = validation_loss\n",
    "        print(f\"Completed {epoch} out of {number_epochs} training epochs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, f):\n",
    "        super().__init__()\n",
    "        self._f = f\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self._f(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5 = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    LambdaLayer(lambda X: X.view(X.size(0), -1)),\n",
    "    nn.Linear(256, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(84, 10)\n",
    ")\n",
    "lenet5.to(DEVICE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "opt = optim.Adam(lenet5.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(lenet5, loss_fn, training_data_loader, opt, validation_data_loader, number_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions using the test data\n",
    "\n",
    "### Load the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_testing_features = np.loadtxt(\"../input/test.csv\", delimiter=',', skiprows=1, dtype=np.int64)\n",
    "_scaled_testing_features = np.divide(_testing_features, 255, dtype=np.float32)\n",
    "scaled_testing_features_tensor = torch.from_numpy(_scaled_testing_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset the model parameters using the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"checkpoint.pkl\")\n",
    "lenet5.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "lenet5.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = lenet5(scaled_testing_features_tensor.view(-1, 1, 28, 28).to(DEVICE))\n",
    "predictions = torch.argmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visually check model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , axes = plt.subplots(5, 5, sharex=True, sharey=True, figsize=(20, 20))\n",
    "idx = 0\n",
    "for i  in range(5):\n",
    "    for j in range(5):\n",
    "        _ = axes[i, j].imshow(scaled_testing_features_tensor[idx].reshape((28, 28)), cmap=\"gray\")\n",
    "        axes[i, j].set_title(f\"Predicted digit: {predictions[idx]}\")\n",
    "        idx += 1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission format for kaggle\n",
    "!head ../input/sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "number_predictions, = predictions.shape\n",
    "(pd.DataFrame({\"ImageId\": range(1, number_predictions + 1), \"Label\": predictions.cpu()})\n",
    "   .to_csv(f\"submission-{timestamp}.csv\", index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head submission-*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to Kaggle!\n",
    "\n",
    "Once you have successfully submited your predictions then you can check the [Digit-Recognizer competition](https://www.kaggle.com/c/digit-recognizer) website and see how well your best model compares to your peers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export KAGGLE_USERNAME=\"YOUR_USERNAME\"\n",
    "export KAGGLE_KEY=\"YOUR_API_KEY\"\n",
    "kaggle competitions submit digit-recognizer \\\n",
    "  -f $(ls ../data/kaggle-submissions/mnist/submission-*.csv | tail -n 1) \\\n",
    "  -m \"My first digit recognizer submission!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
