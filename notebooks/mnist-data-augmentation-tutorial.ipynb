{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn import model_selection\nimport torch\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils import data\nfrom torchvision import models, transforms","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Improving Performance with Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist_arr = np.loadtxt(\"../input/train.csv\", delimiter=',', skiprows=1, dtype=np.uint8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split training data into training and validation subsets\n\n**First step is to split the raw training data into training and validation datasets. The validation dataset will be used to help us prevent overfitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"_prng = np.random.RandomState(42)\ntraining_features, validation_features, training_target, validation_target = (\n    model_selection.train_test_split(mnist_arr[:, 1:],\n                                     mnist_arr[:, 0],\n                                     test_size=0.10,\n                                     random_state=_prng)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create custom `DataSet` class to handle transformations"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataSetWithTransforms(data.Dataset):\n    \n    def __init__(self, features, target, feature_transforms=None):\n        super().__init__()\n        self._features = features\n        self._target = torch.from_numpy(target).long()\n        self._feature_transforms = feature_transforms\n        \n    def __getitem__(self, index):\n        if self._feature_transforms is None:\n            features = self._features[index]\n        else: \n            features = self._feature_transforms(self._features[index])\n        target = self._target[index]\n        return (features, target) \n    \n    def __len__(self):\n        n_samples, _ = self._features.shape\n        return n_samples\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data augmentation should only apply to training data\n_feature_transforms = transforms.Compose([\n    transforms.Lambda(lambda array: array.reshape((28, 28, 1))),\n    transforms.ToPILImage(),\n    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), shear=15, scale=(1.0, 1.1)),\n    transforms.ToTensor(),\n])\n\ntraining_dataset = DataSetWithTransforms(training_features, training_target, _feature_transforms)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data augmentation should not be applied to validation data\n_feature_transforms = transforms.Compose([\n    transforms.Lambda(lambda array: array.reshape((28, 28, 1))),\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n])\n\nvalidation_dataset = DataSetWithTransforms(validation_features, validation_target, _feature_transforms)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create a custom DataLoader**** for training and validation datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"class WrappedDataLoader:\n    \n    def __init__(self, data_loader, f):\n        self._data_loader = data_loader\n        self._f = f\n        \n    def __len__(self):\n        return len(self._data_loader)\n    \n    def __iter__(self):\n        for batch in iter(self._data_loader):\n            yield self._f(*batch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_batch_size = 32\n_training_data_loader = data.DataLoader(training_dataset, batch_size=_batch_size, shuffle=True)\ntraining_data_loader = WrappedDataLoader(_training_data_loader, lambda X, y: (X.to(DEVICE), y.to(DEVICE)))\n_validation_data_loader = data.DataLoader(validation_dataset, batch_size=1024)\nvalidation_data_loader = WrappedDataLoader(_validation_data_loader, lambda X, y: (X.to(DEVICE), y.to(DEVICE)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploring transformed images"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(5, 6, sharex=True, sharey=True, figsize=(20, 20))\nfor i in range(5):\n    for j in range(6):\n        if j == 0:\n            _ = axes[i, j].imshow(training_features[i].reshape((28, 28)), cmap=\"gray\")\n        else:\n            _ = axes[i, j].imshow(training_dataset[i][0][0], cmap=\"gray\")\n        \n        if i == 0 and j == 0:\n            axes[i, j].set_title(\"Original Digit\")\n        if i == 0 and j > 0:\n            axes[i, j].set_title(f\"Augmented Digit {j}\")        \nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train a CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"def _checkpoint(epoch, model_fn, opt, path):\n    kwargs = {\"epoch\": epoch,\n              \"model_state_dict\": model_fn.state_dict(),\n              \"optimizer_state_dict\": opt.state_dict()}\n    torch.save(kwargs, path)\n\n\ndef _partial_fit(model_fn, loss_fn, X_batch, y_batch, opt):\n    # forward pass\n    loss = loss_fn(model_fn(X_batch), y_batch)\n\n    # back propagation\n    loss.backward()\n    opt.step()\n    opt.zero_grad() # don't forget to reset the gradient after each batch!\n\n\ndef fit(model_fn, loss_fn, training_data_loader, opt, validation_data_loader=None, number_epochs=1, path=\"checkpoint.pkl\"):\n    lowest_validation_loss = np.inf # initialize validation loss for checkpointing!\n    for epoch in range(number_epochs):\n        model_fn.train()\n        for X_batch, y_batch in training_data_loader:\n            _partial_fit(model_fn, loss_fn, X_batch, y_batch, opt)\n        \n        # compute validation loss after each training epoch\n        if validation_data_loader is not None:\n            model_fn.eval()\n            with torch.no_grad():\n                batch_losses, batch_sizes = zip(*[(loss_fn(model_fn(X), y), len(X)) for X, y in validation_data_loader])\n                validation_loss = np.sum(np.multiply(batch_losses, batch_sizes)) / np.sum(batch_sizes)\n                if validation_loss < lowest_validation_loss:\n                    print(f\"Training epoch: {epoch}, Lowest validation loss: {validation_loss}\")\n                    _checkpoint(epoch, model_fn, opt, path)\n                    lowest_validation_loss = validation_loss\n        print(f\"Completed {epoch} out of {number_epochs} training epochs.\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LambdaLayer(nn.Module):\n    \n    def __init__(self, f):\n        super().__init__()\n        self._f = f\n        \n    def forward(self, X):\n        return self._f(X)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lenet5 = nn.Sequential(\n    nn.Conv2d(1, 6, kernel_size=5),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Conv2d(6, 16, kernel_size=5),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    LambdaLayer(lambda X: X.view(X.size(0), -1)),\n    nn.Linear(256, 120),\n    nn.ReLU(),\n    nn.Linear(120, 84),\n    nn.ReLU(),\n    nn.Linear(84, 10)\n)\nlenet5.to(DEVICE)\n\nloss_fn = nn.CrossEntropyLoss()\n\nopt = optim.Adam(lenet5.parameters())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit(lenet5, loss_fn, training_data_loader, opt, validation_data_loader, number_epochs=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make predictions using the test data\n\n### Load the testing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"_testing_features = np.loadtxt(\"../input/test.csv\", delimiter=',', skiprows=1, dtype=np.int64)\n_scaled_testing_features = np.divide(_testing_features, 255, dtype=np.float32)\nscaled_testing_features_tensor = torch.from_numpy(_scaled_testing_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reset the model parameters using the checkpoint"},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = torch.load(\"checkpoint.pkl\")\nlenet5.load_state_dict(checkpoint[\"model_state_dict\"])\nlenet5.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = lenet5(scaled_testing_features_tensor.view(-1, 1, 28, 28).to(DEVICE))\npredictions = torch.argmax(output, dim=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visually check model predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig , axes = plt.subplots(5, 5, sharex=True, sharey=True, figsize=(20, 20))\nidx = 0\nfor i  in range(5):\n    for j in range(5):\n        _ = axes[i, j].imshow(scaled_testing_features_tensor[idx].reshape((28, 28)), cmap=\"gray\")\n        axes[i, j].set_title(f\"Predicted digit: {predictions[idx]}\")\n        idx += 1\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reformat predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission format for kaggle\n!head ../input/sample_submission.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\nimport pandas as pd\n\ntimestamp = time.strftime(\"%Y%m%d-%H%M%S\")\nnumber_predictions, = predictions.shape\n(pd.DataFrame({\"ImageId\": range(1, number_predictions + 1), \"Label\": predictions.cpu()})\n   .to_csv(f\"submission-{timestamp}.csv\", index=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!head submission-*.csv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submit to Kaggle!\n\nOnce you have successfully submited your predictions then you can check the [Digit-Recognizer competition](https://www.kaggle.com/c/digit-recognizer) website and see how well your best model compares to your peers."},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}